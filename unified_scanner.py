#!/usr/bin/env python3
"""
Kalshi ç»Ÿä¸€æ‰«æå™¨

ä¸¤å±‚æ‰«æç­–ç•¥ï¼š
1. Events å±‚ - è·å–æ‰€æœ‰ open eventsï¼ŒæŒ‰ category è¿‡æ»¤
2. Markets å±‚ - è·å–æ¯ä¸ª event çš„å¸‚åœºï¼Œæ£€æµ‹ tier

ä¸ä¾èµ–ç¡¬ç¼–ç  series åˆ—è¡¨ï¼Œè‡ªåŠ¨å‘ç°æ–°å¸‚åœºã€‚

Author: OpenClaw
Date: 2026-02-20
"""

import os
import sys
import json
import requests
import time
from datetime import datetime, timezone
from pathlib import Path
from collections import defaultdict

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
from source_detector import detect_sources

API_BASE = "https://api.elections.kalshi.com/trade-api/v2"
DATA_DIR = Path(__file__).parent / "data"

# å…³æ³¨çš„ç±»åˆ« (æ’é™¤ Sports, Entertainment, Esports)
TARGET_CATEGORIES = {"Economics", "Politics", "Financials", "Elections", "World", "Companies"}

# æ’é™¤çš„ series å‰ç¼€ (æœ‰ç‹¬ç«‹ç³»ç»Ÿå¤„ç†)
EXCLUDE_PREFIXES = {"KXHIGH", "KXLOW"}  # å¤©æ°”å¸‚åœº


class UnifiedScanner:
    """ç»Ÿä¸€æ‰«æå™¨"""
    
    def __init__(self, min_volume: int = 100, max_days: int = 90, min_tier: int = 3):
        self.min_volume = min_volume
        self.max_days = max_days
        self.min_tier = min_tier  # æœ€é«˜æ¥å—çš„ tier (1=æœ€å¥½, 9=æœ€å·®)
        self.now = datetime.now(timezone.utc)
    
    def fetch_all_events(self) -> list:
        """è·å–æ‰€æœ‰ open events"""
        events = []
        cursor = None
        
        for _ in range(50):  # æœ€å¤š 5000 ä¸ª events
            params = {"limit": 100, "status": "open"}
            if cursor:
                params["cursor"] = cursor
            
            try:
                resp = requests.get(f"{API_BASE}/events", params=params, timeout=15)
                if resp.status_code == 429:
                    time.sleep(3)
                    continue
                if resp.status_code != 200:
                    break
                
                data = resp.json()
                events.extend(data.get("events", []))
                
                cursor = data.get("cursor")
                if not cursor:
                    break
                
                time.sleep(0.1)
            except Exception as e:
                print(f"Error fetching events: {e}")
                break
        
        return events
    
    def filter_events(self, events: list) -> list:
        """æŒ‰ç±»åˆ«è¿‡æ»¤ events"""
        filtered = []
        for e in events:
            category = e.get("category", "")
            series = e.get("series_ticker") or e.get("event_ticker", "").split("-")[0]
            
            # è·³è¿‡éç›®æ ‡ç±»åˆ«
            if category not in TARGET_CATEGORIES:
                continue
            
            # è·³è¿‡å¤©æ°”å¸‚åœº
            if any(series.startswith(prefix) for prefix in EXCLUDE_PREFIXES):
                continue
            
            filtered.append(e)
        
        return filtered
    
    def analyze_event(self, event: dict) -> dict | None:
        """åˆ†æå•ä¸ª eventï¼Œè¿”å›å¸‚åœºä¿¡æ¯"""
        event_ticker = event.get("event_ticker", "")
        
        try:
            resp = requests.get(f"{API_BASE}/markets", params={
                "event_ticker": event_ticker,
                "status": "open",
                "limit": 10
            }, timeout=10)
            
            if resp.status_code != 200:
                return None
            
            markets = resp.json().get("markets", [])
            if not markets:
                return None
            
            # æ±‡æ€»æ‰€æœ‰å¸‚åœº
            total_volume = sum(m.get("volume", 0) for m in markets)
            
            # æ£€æŸ¥ç¬¬ä¸€ä¸ªå¸‚åœºçš„ tier
            m = markets[0]
            rules = m.get("rules_primary", "")
            title = m.get("title", "")
            
            result = detect_sources(rules, title)
            tier = result.get("research_tier", 9)
            sources = result.get("sources", [])
            
            # è®¡ç®—åˆ°æœŸå¤©æ•°
            close_time_str = m.get("close_time", "")
            try:
                close_time = datetime.fromisoformat(close_time_str.replace("Z", "+00:00"))
                days_left = (close_time - self.now).days
            except:
                days_left = 9999
            
            return {
                "event_ticker": event_ticker,
                "series": event.get("series_ticker") or event_ticker.split("-")[0],
                "category": event.get("category", ""),
                "title": event.get("title", "")[:60],
                "tier": tier,
                "sources": sources,
                "volume": total_volume,
                "days_left": days_left,
                "market_count": len(markets),
                "markets": [m.get("ticker") for m in markets[:5]],
            }
            
        except Exception as e:
            return None
    
    def scan(self, verbose: bool = True) -> dict:
        """æ‰§è¡Œå®Œæ•´æ‰«æ"""
        if verbose:
            print("ğŸ“¡ è·å–æ‰€æœ‰ Events...")
        
        events = self.fetch_all_events()
        if verbose:
            print(f"   å…± {len(events)} ä¸ª events")
        
        # è¿‡æ»¤
        filtered = self.filter_events(events)
        if verbose:
            print(f"   ç›®æ ‡ç±»åˆ«: {len(filtered)} ä¸ª events")
        
        # åˆ†ææ¯ä¸ª event
        results = []
        for i, e in enumerate(filtered):
            info = self.analyze_event(e)
            if info:
                # åº”ç”¨è¿‡æ»¤æ¡ä»¶
                if info["volume"] >= self.min_volume and \
                   info["days_left"] <= self.max_days and \
                   info["tier"] <= self.min_tier:
                    results.append(info)
            
            if verbose and i % 50 == 0 and i > 0:
                print(f"   å·²åˆ†æ {i}/{len(filtered)}...")
            
            time.sleep(0.08)
        
        # æŒ‰ tier å’Œ volume æ’åº
        results.sort(key=lambda x: (x["tier"], -x["volume"]))
        
        # ç”ŸæˆæŠ¥å‘Š
        report = {
            "scan_time": self.now.isoformat(),
            "filters": {
                "min_volume": self.min_volume,
                "max_days": self.max_days,
                "min_tier": self.min_tier,
            },
            "total_events": len(events),
            "filtered_events": len(filtered),
            "matched_markets": len(results),
            "results": results,
        }
        
        return report
    
    def print_report(self, report: dict):
        """æ‰“å°æŠ¥å‘Š"""
        print("\n" + "=" * 70)
        print("ğŸ“Š KALSHI å¸‚åœºæ‰«ææŠ¥å‘Š")
        print("=" * 70)
        print(f"æ‰«ææ—¶é—´: {report['scan_time'][:19]}")
        print(f"è¿‡æ»¤æ¡ä»¶: volumeâ‰¥{report['filters']['min_volume']}, "
              f"daysâ‰¤{report['filters']['max_days']}, tierâ‰¤{report['filters']['min_tier']}")
        print(f"æ€» Events: {report['total_events']} â†’ ç›®æ ‡ç±»åˆ«: {report['filtered_events']} â†’ åŒ¹é…: {report['matched_markets']}")
        
        results = report["results"]
        
        # åˆ†ç»„æ˜¾ç¤º
        tier_1_2 = [r for r in results if r["tier"] <= 2]
        tier_3 = [r for r in results if r["tier"] == 3]
        
        print(f"\n### âœ… Tier 1-2 å¯ç ”ç©¶ ({len(tier_1_2)} ä¸ª)\n")
        for r in tier_1_2:
            print(f"  Tier {r['tier']} | {r['days_left']:>3}å¤© | vol={r['volume']:>7} | {r['series']}")
            print(f"       {r['title']}")
            print(f"       Sources: {r['sources']}, Markets: {r['market_count']}")
            print()
        
        if tier_3:
            print(f"\n### âš ï¸ Tier 3 éœ€åˆ¤æ–­ ({len(tier_3)} ä¸ª)\n")
            for r in tier_3[:5]:
                print(f"  {r['days_left']:>3}å¤© | vol={r['volume']:>7} | {r['series']}: {r['title'][:40]}")
        
        print("\n" + "=" * 70)
    
    def save_watchlist(self, report: dict, path: Path = None):
        """ä¿å­˜ watchlist"""
        path = path or (DATA_DIR / "watchlist_unified.json")
        path.parent.mkdir(parents=True, exist_ok=True)
        
        watchlist = {
            "updated": report["scan_time"],
            "filters": report["filters"],
            "tier_1_2": [r for r in report["results"] if r["tier"] <= 2],
            "tier_3": [r for r in report["results"] if r["tier"] == 3],
        }
        
        with open(path, "w") as f:
            json.dump(watchlist, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ’¾ Watchlist å·²ä¿å­˜: {path}")


def main():
    import argparse
    
    parser = argparse.ArgumentParser(description="Kalshi ç»Ÿä¸€æ‰«æå™¨")
    parser.add_argument("--min-volume", type=int, default=100, help="æœ€å° volume")
    parser.add_argument("--max-days", type=int, default=90, help="æœ€å¤§åˆ°æœŸå¤©æ•°")
    parser.add_argument("--min-tier", type=int, default=3, help="æœ€é«˜æ¥å—çš„ tier")
    parser.add_argument("--save", action="store_true", help="ä¿å­˜ watchlist")
    
    args = parser.parse_args()
    
    scanner = UnifiedScanner(
        min_volume=args.min_volume,
        max_days=args.max_days,
        min_tier=args.min_tier
    )
    
    report = scanner.scan()
    scanner.print_report(report)
    
    if args.save:
        scanner.save_watchlist(report)


if __name__ == "__main__":
    main()
