#!/usr/bin/env python3
"""
Kalshi å¸‚åœºæ™®æŸ¥å·¥å…·

å…¨é¢æ‰«ææ‰€æœ‰å¸‚åœºï¼Œåˆ†ç±»å¹¶ç”Ÿæˆ watchlistã€‚
æ¯å‘¨/åŒå‘¨è¿è¡Œä¸€æ¬¡æ›´æ–°ã€‚

ç”¨æ³•:
    python3 market_census.py              # å®Œæ•´æ‰«æ
    python3 market_census.py --summary    # åªçœ‹æ‘˜è¦
    python3 market_census.py --update     # æ›´æ–°ç°æœ‰ watchlist

Author: OpenClaw
Date: 2026-02-21
"""

import os
import sys
import json
import argparse
import requests
import time
import re
from datetime import datetime, timezone
from typing import List, Dict, Set
from pathlib import Path
from collections import defaultdict

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
from source_detector import detect_sources

API_BASE = "https://api.elections.kalshi.com/trade-api/v2"
DATA_DIR = Path(__file__).parent / "data"
CENSUS_FILE = DATA_DIR / "market_census.json"
WATCHLIST_FILE = DATA_DIR / "watchlist_series.json"


class MarketCensus:
    """Kalshi å¸‚åœºæ™®æŸ¥"""
    
    def __init__(self):
        self.markets = []
        self.events = []
        self.series = defaultdict(lambda: {
            "markets": [],
            "category": "",
            "tier": 9,
            "sources": [],
            "total_volume": 0,
            "earliest_close": None,
            "latest_close": None,
        })
    
    def fetch_all_events(self) -> List[Dict]:
        """è·å–æ‰€æœ‰ events"""
        events = []
        cursor = None
        
        print("ğŸ“¡ è·å– Events...")
        for page in range(100):
            try:
                params = {"limit": 100, "status": "open"}
                if cursor:
                    params["cursor"] = cursor
                
                resp = requests.get(f"{API_BASE}/events", params=params, timeout=15)
                if resp.status_code != 200:
                    print(f"   âš ï¸ Events API error: {resp.status_code}")
                    break
                
                data = resp.json()
                batch = data.get("events", [])
                events.extend(batch)
                
                cursor = data.get("cursor")
                if not cursor or len(batch) < 100:
                    break
                
                print(f"   å·²è·å– {len(events)} ä¸ª events...")
                    
            except Exception as e:
                print(f"   âŒ Error: {e}")
                break
        
        print(f"   âœ… å…± {len(events)} ä¸ª events")
        return events
    
    def fetch_all_markets(self) -> List[Dict]:
        """è·å–æ‰€æœ‰ marketsï¼ˆå¸¦é™æµå¤„ç†ï¼‰"""
        markets = []
        cursor = None
        
        print("ğŸ“¡ è·å– Markets...")
        for page in range(200):  # æœ€å¤š 20000 ä¸ªå¸‚åœº
            try:
                params = {"limit": 100, "status": "open"}
                if cursor:
                    params["cursor"] = cursor
                
                resp = requests.get(f"{API_BASE}/markets", params=params, timeout=15)
                
                # å¤„ç†é™æµ
                if resp.status_code == 429:
                    print(f"   âš ï¸ é™æµï¼Œç­‰å¾… 5 ç§’...")
                    time.sleep(5)
                    continue
                
                if resp.status_code != 200:
                    print(f"   âš ï¸ Markets API error: {resp.status_code}")
                    break
                
                data = resp.json()
                batch = data.get("markets", [])
                markets.extend(batch)
                
                cursor = data.get("cursor")
                if not cursor or len(batch) < 100:
                    break
                
                if page % 10 == 0:
                    print(f"   å·²è·å– {len(markets)} ä¸ª markets...")
                
                # é™æµä¿æŠ¤
                time.sleep(0.2)
                    
            except Exception as e:
                print(f"   âŒ Error: {e}")
                break
        
        print(f"   âœ… å…± {len(markets)} ä¸ª markets")
        return markets
    
    def extract_series(self, ticker: str, event_ticker: str = "") -> str:
        """ä» ticker æˆ– event_ticker æå– series"""
        # ä¼˜å…ˆç”¨ event_ticker çš„å‰ç¼€
        if event_ticker:
            # KXMVESPORTSMULTIGAMEEXTENDED-S2026... -> KXMVESPORTSMULTIGAMEEXTENDED
            match = re.match(r'^([A-Z]+)', event_ticker)
            if match:
                return match.group(1)
        
        # ä» ticker æå–
        # KXGDP-26APR30-T4.0 -> KXGDP
        match = re.match(r'^([A-Z]+)', ticker)
        if match:
            return match.group(1)
        
        return ticker.split("-")[0] if "-" in ticker else ticker
    
    def analyze_markets(self, markets: List[Dict]):
        """åˆ†ææ‰€æœ‰å¸‚åœºï¼ŒæŒ‰ series åˆ†ç»„"""
        print("ğŸ” åˆ†æå¸‚åœº...")
        
        # å…ˆè·å– events ä»¥è·å– category
        event_categories = {}
        print("   è·å– event åˆ†ç±»ä¿¡æ¯...")
        for page in range(10):
            try:
                resp = requests.get(f"{API_BASE}/events", params={
                    "limit": 100, "status": "open", "cursor": None
                }, timeout=15)
                if resp.status_code == 200:
                    for e in resp.json().get("events", []):
                        event_categories[e.get("event_ticker", "")] = e.get("category", "Unknown")
                time.sleep(0.2)
            except:
                break
        
        for m in markets:
            ticker = m.get("ticker", "")
            title = m.get("title", "")
            rules = m.get("rules_primary", "")
            event_ticker = m.get("event_ticker", "")
            series_ticker = self.extract_series(ticker, event_ticker)
            category = event_categories.get(event_ticker, m.get("category", "Unknown") or "Unknown")
            volume = m.get("volume_24h", 0) or m.get("volume", 0) or 0
            close_time = m.get("close_time", "")
            
            # æ£€æµ‹ tier
            result = detect_sources(rules, title)
            tier = result.get("research_tier", 9)
            sources = result.get("sources", [])
            
            # æ›´æ–° series ä¿¡æ¯
            s = self.series[series_ticker]
            s["markets"].append({
                "ticker": ticker,
                "title": title[:100],
                "volume": volume,
                "close_time": close_time,
                "tier": tier,
            })
            s["category"] = category
            s["total_volume"] += volume
            
            # ä¿ç•™æœ€å¥½çš„ tier
            if tier < s["tier"]:
                s["tier"] = tier
                s["sources"] = sources
            
            # æ›´æ–°åˆ°æœŸæ—¶é—´èŒƒå›´
            if close_time:
                if not s["earliest_close"] or close_time < s["earliest_close"]:
                    s["earliest_close"] = close_time
                if not s["latest_close"] or close_time > s["latest_close"]:
                    s["latest_close"] = close_time
        
        print(f"   âœ… åˆ†æå®Œæˆï¼Œå…± {len(self.series)} ä¸ª series")
    
    def generate_report(self) -> Dict:
        """ç”ŸæˆæŠ¥å‘Š"""
        now = datetime.now(timezone.utc)
        
        report = {
            "generated_at": now.isoformat(),
            "total_markets": sum(len(s["markets"]) for s in self.series.values()),
            "total_series": len(self.series),
            "by_tier": defaultdict(list),
            "by_category": defaultdict(list),
            "recommended_watchlist": [],
        }
        
        for series_ticker, s in self.series.items():
            tier = s["tier"]
            category = s["category"]
            
            # è®¡ç®—åˆ°æœŸå¤©æ•°
            days_to_earliest = None
            if s["earliest_close"]:
                try:
                    close_time = datetime.fromisoformat(s["earliest_close"].replace("Z", "+00:00"))
                    days_to_earliest = (close_time - now).days
                except:
                    pass
            
            series_info = {
                "series_ticker": series_ticker,
                "category": category,
                "tier": tier,
                "sources": s["sources"],
                "market_count": len(s["markets"]),
                "total_volume": s["total_volume"],
                "days_to_earliest": days_to_earliest,
                "earliest_close": s["earliest_close"],
            }
            
            report["by_tier"][f"tier_{tier}"].append(series_info)
            report["by_category"][category].append(series_info)
            
            # æ¨è watchlist: tier 1-2ï¼Œæœ‰ volume
            if tier <= 2 and s["total_volume"] > 0:
                report["recommended_watchlist"].append(series_info)
        
        # æ’åº
        report["recommended_watchlist"].sort(key=lambda x: (-x["total_volume"]))
        
        return report
    
    def save_census(self, report: Dict):
        """ä¿å­˜æ™®æŸ¥ç»“æœ"""
        DATA_DIR.mkdir(parents=True, exist_ok=True)
        
        # ä¿å­˜å®Œæ•´æŠ¥å‘Š
        with open(CENSUS_FILE, "w") as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        print(f"ğŸ’¾ æ™®æŸ¥ç»“æœå·²ä¿å­˜: {CENSUS_FILE}")
        
        # ä¿å­˜ watchlist
        watchlist = {
            "updated_at": report["generated_at"],
            "series": [s["series_ticker"] for s in report["recommended_watchlist"]],
            "details": report["recommended_watchlist"],
        }
        with open(WATCHLIST_FILE, "w") as f:
            json.dump(watchlist, f, indent=2, ensure_ascii=False)
        print(f"ğŸ’¾ Watchlist å·²ä¿å­˜: {WATCHLIST_FILE}")
    
    def print_summary(self, report: Dict):
        """æ‰“å°æ‘˜è¦"""
        print("\n" + "=" * 60)
        print("ğŸ“Š KALSHI å¸‚åœºæ™®æŸ¥æŠ¥å‘Š")
        print("=" * 60)
        print(f"ç”Ÿæˆæ—¶é—´: {report['generated_at'][:19]}")
        print(f"æ€»å¸‚åœºæ•°: {report['total_markets']}")
        print(f"æ€» Series: {report['total_series']}")
        
        print("\n### æŒ‰ Tier åˆ†å¸ƒ")
        for tier in sorted(report["by_tier"].keys()):
            count = len(report["by_tier"][tier])
            print(f"  {tier}: {count} ä¸ª series")
        
        print("\n### æŒ‰ç±»åˆ«åˆ†å¸ƒ (Top 10)")
        sorted_cats = sorted(report["by_category"].items(), key=lambda x: -len(x[1]))
        for cat, series_list in sorted_cats[:10]:
            print(f"  {cat}: {len(series_list)} ä¸ª series")
        
        print("\n### æ¨è Watchlist (Tier 1-2, æœ‰äº¤æ˜“é‡)")
        watchlist = report["recommended_watchlist"]
        if watchlist:
            print(f"å…± {len(watchlist)} ä¸ª series:\n")
            for s in watchlist[:20]:
                days = s.get("days_to_earliest")
                days_str = f"{days}å¤©" if days else "?"
                print(f"  âœ… {s['series_ticker']:<25} | Tier {s['tier']} | {s['category']:<15} | vol={s['total_volume']:>6} | {days_str}")
                print(f"     Sources: {', '.join(s['sources']) if s['sources'] else '-'}")
        else:
            print("  (æ— )")
        
        print("\n" + "=" * 60)
    
    def fetch_events_by_category(self) -> Dict[str, List[Dict]]:
        """è·å–æ‰€æœ‰ events å¹¶æŒ‰ category åˆ†ç±»"""
        events_by_cat = defaultdict(list)
        cursor = None
        
        print("ğŸ“¡ è·å–æ‰€æœ‰ Events...")
        for page in range(50):
            try:
                params = {"limit": 100, "status": "open"}
                if cursor:
                    params["cursor"] = cursor
                
                resp = requests.get(f"{API_BASE}/events", params=params, timeout=15)
                
                if resp.status_code == 429:
                    time.sleep(5)
                    continue
                
                if resp.status_code != 200:
                    break
                
                data = resp.json()
                batch = data.get("events", [])
                
                for e in batch:
                    cat = e.get("category", "Unknown")
                    events_by_cat[cat].append(e)
                
                cursor = data.get("cursor")
                if not cursor or len(batch) < 100:
                    break
                
                time.sleep(0.2)
                
            except Exception as e:
                print(f"   âŒ Error: {e}")
                break
        
        total = sum(len(v) for v in events_by_cat.values())
        print(f"   âœ… å…± {total} ä¸ª events")
        return dict(events_by_cat)
    
    def fetch_markets_for_events(self, events: List[Dict]) -> List[Dict]:
        """è·å–æŒ‡å®š events çš„æ‰€æœ‰ markets"""
        markets = []
        
        for i, e in enumerate(events):
            try:
                event_ticker = e.get("event_ticker", "")
                if not event_ticker:
                    continue
                
                resp = requests.get(f"{API_BASE}/markets", params={
                    "event_ticker": event_ticker,
                    "status": "open",
                    "limit": 50
                }, timeout=15)
                
                if resp.status_code == 429:
                    time.sleep(5)
                    continue
                
                if resp.status_code == 200:
                    batch = resp.json().get("markets", [])
                    # æ·»åŠ  category ä¿¡æ¯
                    for m in batch:
                        m["_category"] = e.get("category", "Unknown")
                        m["_event_title"] = e.get("title", "")
                        m["_series_ticker"] = e.get("series_ticker", "")
                    markets.extend(batch)
                
                time.sleep(0.15)  # é™æµ
                
                if i % 50 == 0 and i > 0:
                    print(f"   å·²å¤„ç† {i}/{len(events)} ä¸ª events, {len(markets)} ä¸ª markets...")
                
            except Exception as ex:
                pass
        
        return markets
    
    def run(self, summary_only: bool = False):
        """è¿è¡Œå®Œæ•´æ™®æŸ¥"""
        if summary_only and CENSUS_FILE.exists():
            with open(CENSUS_FILE) as f:
                report = json.load(f)
            self.print_summary(report)
            return report
        
        # 1. è·å–æ‰€æœ‰ events
        events_by_cat = self.fetch_events_by_category()
        
        print("\nğŸ“Š Events åˆ†å¸ƒ:")
        for cat, evts in sorted(events_by_cat.items(), key=lambda x: -len(x[1])):
            print(f"   {cat}: {len(evts)}")
        
        # 2. ä¼˜å…ˆå¤„ç†æœ‰æ„ä¹‰çš„ç±»åˆ«
        priority_categories = ["Economics", "Politics", "Financials", "Elections", "World"]
        other_categories = [c for c in events_by_cat.keys() if c not in priority_categories]
        
        all_events = []
        for cat in priority_categories:
            all_events.extend(events_by_cat.get(cat, []))
        # å…¶ä»–ç±»åˆ«ä¹ŸåŠ å…¥
        for cat in other_categories:
            all_events.extend(events_by_cat.get(cat, []))
        
        print(f"\nğŸ“¡ è·å– {len(all_events)} ä¸ª events çš„ markets...")
        self.markets = self.fetch_markets_for_events(all_events)
        print(f"   âœ… å…±è·å– {len(self.markets)} ä¸ª markets")
        
        # 3. åˆ†æ
        self.analyze_markets_v2(self.markets)
        
        # 4. ç”ŸæˆæŠ¥å‘Š
        report = self.generate_report()
        
        # 5. ä¿å­˜
        self.save_census(report)
        
        # 6. æ‰“å°æ‘˜è¦
        self.print_summary(report)
        
        return report
    
    def analyze_markets_v2(self, markets: List[Dict]):
        """åˆ†æå¸‚åœº V2 - ä½¿ç”¨é¢„ç½®çš„ category ä¿¡æ¯"""
        print("ğŸ” åˆ†æå¸‚åœº...")
        
        for m in markets:
            ticker = m.get("ticker", "")
            title = m.get("title", "")
            rules = m.get("rules_primary", "")
            series_ticker = m.get("_series_ticker") or self.extract_series(ticker, m.get("event_ticker", ""))
            category = m.get("_category", "Unknown")
            volume = m.get("volume_24h", 0) or m.get("volume", 0) or 0
            close_time = m.get("close_time", "")
            
            # æ£€æµ‹ tier
            result = detect_sources(rules, title)
            tier = result.get("research_tier", 9)
            sources = result.get("sources", [])
            
            # æ›´æ–° series ä¿¡æ¯
            s = self.series[series_ticker]
            s["markets"].append({
                "ticker": ticker,
                "title": title[:100],
                "volume": volume,
                "close_time": close_time,
                "tier": tier,
            })
            s["category"] = category
            s["total_volume"] += volume
            
            # ä¿ç•™æœ€å¥½çš„ tier
            if tier < s["tier"]:
                s["tier"] = tier
                s["sources"] = sources
            
            # æ›´æ–°åˆ°æœŸæ—¶é—´èŒƒå›´
            if close_time:
                if not s["earliest_close"] or close_time < s["earliest_close"]:
                    s["earliest_close"] = close_time
                if not s["latest_close"] or close_time > s["latest_close"]:
                    s["latest_close"] = close_time
        
        print(f"   âœ… åˆ†æå®Œæˆï¼Œå…± {len(self.series)} ä¸ª series")


def main():
    parser = argparse.ArgumentParser(description="Kalshi å¸‚åœºæ™®æŸ¥")
    parser.add_argument("--summary", action="store_true", help="åªæ˜¾ç¤ºç°æœ‰æŠ¥å‘Šæ‘˜è¦")
    parser.add_argument("--update", action="store_true", help="æ›´æ–° watchlist")
    
    args = parser.parse_args()
    
    census = MarketCensus()
    census.run(summary_only=args.summary)


if __name__ == "__main__":
    main()
