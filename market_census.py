#!/usr/bin/env python3
"""
market_census - Kalshi å¸‚åœºæ™®æŸ¥å·¥å…·

åŠŸèƒ½ï¼š
    - æ‰«ææ‰€æœ‰ Kalshi å¸‚åœº
    - æŒ‰ series åˆ†ç±»
    - ç”Ÿæˆ watchlist_series.json
    - è¯†åˆ« Tier 1/2 å¸‚åœº

ç”¨æ³•ï¼š
    python market_census.py                      # è¿è¡Œæ™®æŸ¥
    python market_census.py --output watchlist.json
    
ä¾èµ–ï¼š
    - requests
"""

import os
import sys
import json
import argparse
import requests
import time
import re
from datetime import datetime, timezone
from typing import List, Dict, Set
from pathlib import Path
from collections import defaultdict

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
from source_detector import detect_sources

API_BASE = "https://api.elections.kalshi.com/trade-api/v2"
DATA_DIR = Path(__file__).parent / "data"
CENSUS_FILE = DATA_DIR / "market_census.json"
WATCHLIST_FILE = DATA_DIR / "watchlist_series.json"

# å·²çŸ¥çš„é‡è¦ series (ä¼˜å…ˆæ‰«æ)
# åˆ†å±‚: Tier 1 æœ‰ Nowcast, Tier 2 æœ‰å®˜æ–¹æ•°æ®æº
PRIORITY_SERIES = [
    # Tier 1 - æœ‰ Nowcast æ•°æ®
    "KXGDP",           # GDP - Atlanta Fed GDPNow
    "KXCPI",           # CPI - Cleveland Fed Nowcast
    "KXPCE",           # PCE - BEA
    "KXFED",           # Fed rate - CME FedWatch
    "KXFOMC",          # FOMC decisions
    "KXRATECUTCOUNT",  # Rate cut count
    "KXJOBLESS",       # Jobless claims - DOL
    "KXUNEMPLOY",      # Unemployment - BLS
    # Tier 2 - æœ‰å®˜æ–¹æ•°æ®æº
    "KXAAGAS",         # AAA Gas price
    "KXGASMAX",        # Gas max
    "KXGASAVG",        # Gas average
    "KXSHUTDOWN",      # Government shutdown
    "KXDHSFUND",       # DHS funding
    "KXDEBT",          # Debt ceiling
    "KXTARIFF",        # Tariffs
    "KXRECESSION",     # Recession
    "KXCR",            # Continuing resolution
    # Tier 2 - æ”¿æ²» (å¯éªŒè¯)
    "KXEOWEEK",        # Executive orders (weekly)
    "KXEOTRUMPTERM",   # Executive orders (term)
    "KXBILLSIGNED",    # Bills signed
    "KXCABINET",       # Cabinet confirmations
    "KXSCOTUS",        # Supreme Court
    # Tier 2 - Powell Mentions (å†å²è®°å½•åˆ†æ)
    "KXFEDMENTION",    # Powell says X at press conference
]


class MarketCensus:
    """Kalshi å¸‚åœºæ™®æŸ¥"""
    
    def __init__(self):
        self.markets = []
        self.events = []
        self.series = defaultdict(lambda: {
            "markets": [],
            "category": "",
            "tier": 9,
            "sources": [],
            "total_volume": 0,
            "earliest_close": None,
            "latest_close": None,
        })
    
    def fetch_all_events(self) -> List[Dict]:
        """è·å–æ‰€æœ‰ events"""
        events = []
        cursor = None
        
        print("ğŸ“¡ è·å– Events...")
        for page in range(100):
            try:
                params = {"limit": 100, "status": "open"}
                if cursor:
                    params["cursor"] = cursor
                
                resp = requests.get(f"{API_BASE}/events", params=params, timeout=15)
                if resp.status_code != 200:
                    print(f"   âš ï¸ Events API error: {resp.status_code}")
                    break
                
                data = resp.json()
                batch = data.get("events", [])
                events.extend(batch)
                
                cursor = data.get("cursor")
                if not cursor or len(batch) < 100:
                    break
                
                print(f"   å·²è·å– {len(events)} ä¸ª events...")
                    
            except Exception as e:
                print(f"   âŒ Error: {e}")
                break
        
        print(f"   âœ… å…± {len(events)} ä¸ª events")
        return events
    
    def fetch_all_markets(self) -> List[Dict]:
        """è·å–æ‰€æœ‰ marketsï¼ˆå¸¦é™æµå¤„ç†ï¼‰"""
        markets = []
        cursor = None
        
        print("ğŸ“¡ è·å– Markets...")
        for page in range(200):  # æœ€å¤š 20000 ä¸ªå¸‚åœº
            try:
                params = {"limit": 100, "status": "open"}
                if cursor:
                    params["cursor"] = cursor
                
                resp = requests.get(f"{API_BASE}/markets", params=params, timeout=15)
                
                # å¤„ç†é™æµ
                if resp.status_code == 429:
                    print(f"   âš ï¸ é™æµï¼Œç­‰å¾… 5 ç§’...")
                    time.sleep(5)
                    continue
                
                if resp.status_code != 200:
                    print(f"   âš ï¸ Markets API error: {resp.status_code}")
                    break
                
                data = resp.json()
                batch = data.get("markets", [])
                markets.extend(batch)
                
                cursor = data.get("cursor")
                if not cursor or len(batch) < 100:
                    break
                
                if page % 10 == 0:
                    print(f"   å·²è·å– {len(markets)} ä¸ª markets...")
                
                # é™æµä¿æŠ¤
                time.sleep(0.2)
                    
            except Exception as e:
                print(f"   âŒ Error: {e}")
                break
        
        print(f"   âœ… å…± {len(markets)} ä¸ª markets")
        return markets
    
    def extract_series(self, ticker: str, event_ticker: str = "") -> str:
        """ä» ticker æˆ– event_ticker æå– series"""
        # ä¼˜å…ˆç”¨ event_ticker çš„å‰ç¼€
        if event_ticker:
            # KXMVESPORTSMULTIGAMEEXTENDED-S2026... -> KXMVESPORTSMULTIGAMEEXTENDED
            match = re.match(r'^([A-Z]+)', event_ticker)
            if match:
                return match.group(1)
        
        # ä» ticker æå–
        # KXGDP-26APR30-T4.0 -> KXGDP
        match = re.match(r'^([A-Z]+)', ticker)
        if match:
            return match.group(1)
        
        return ticker.split("-")[0] if "-" in ticker else ticker
    
    def fetch_markets_by_series(self, series_ticker: str) -> List[Dict]:
        """è·å–ç‰¹å®š series çš„æ‰€æœ‰å¸‚åœº"""
        markets = []
        cursor = None
        
        for page in range(50):  # æ¯ä¸ª series æœ€å¤š 5000 ä¸ªå¸‚åœº
            try:
                params = {
                    "limit": 100,
                    "series_ticker": series_ticker,
                    "status": "open"
                }
                if cursor:
                    params["cursor"] = cursor
                
                resp = requests.get(f"{API_BASE}/markets", params=params, timeout=15)
                
                if resp.status_code == 429:
                    time.sleep(3)
                    continue
                
                if resp.status_code != 200:
                    break
                
                data = resp.json()
                batch = data.get("markets", [])
                markets.extend(batch)
                
                cursor = data.get("cursor")
                if not cursor or len(batch) < 100:
                    break
                
                time.sleep(0.15)  # é™æµä¿æŠ¤
                    
            except Exception as e:
                print(f"      âš ï¸ {series_ticker} error: {e}")
                break
        
        return markets
    
    def scan_priority_series(self) -> Dict[str, Dict]:
        """æ‰«æä¼˜å…ˆ series åˆ—è¡¨"""
        print("ğŸ“¡ æ‰«æä¼˜å…ˆ Series...")
        results = {}
        
        for i, series in enumerate(PRIORITY_SERIES):
            markets = self.fetch_markets_by_series(series)
            
            if not markets:
                continue
            
            # è·å–ç¬¬ä¸€ä¸ªå¸‚åœºçš„ rules æ¥æ£€æµ‹ tier
            rules = markets[0].get("rules_primary", "")
            title = markets[0].get("title", "")
            result = detect_sources(rules, title)
            
            # è®¡ç®—ç»Ÿè®¡
            total_volume = sum(m.get("volume_24h", 0) or 0 for m in markets)
            close_times = [m.get("close_time") for m in markets if m.get("close_time")]
            earliest = min(close_times) if close_times else None
            
            # è®¡ç®—å¤©æ•°
            days_left = None
            if earliest:
                try:
                    close_dt = datetime.fromisoformat(earliest.replace("Z", "+00:00"))
                    days_left = (close_dt - datetime.now(timezone.utc)).days
                except:
                    pass
            
            results[series] = {
                "series_ticker": series,
                "market_count": len(markets),
                "tier": result.get("research_tier", 9),
                "sources": result.get("sources", []),
                "research_method": result.get("research_method", ""),
                "total_volume": total_volume,
                "days_left": days_left,
                "earliest_close": earliest,
                "sample_title": title[:80] if title else "",
            }
            
            tier_icon = "ğŸŸ¢" if result.get("research_tier", 9) <= 2 else "ğŸŸ¡" if result.get("research_tier", 9) <= 4 else "âšª"
            print(f"   {tier_icon} {series}: {len(markets)} markets, tier {result.get('research_tier', 9)}")
            
            time.sleep(0.2)
        
        print(f"   âœ… æ‰«æå®Œæˆ: {len(results)} ä¸ªæ´»è·ƒ series")
        return results
    
    def analyze_markets(self, markets: List[Dict]):
        """åˆ†ææ‰€æœ‰å¸‚åœºï¼ŒæŒ‰ series åˆ†ç»„"""
        print("ğŸ” åˆ†æå¸‚åœº...")
        
        # å…ˆè·å– events ä»¥è·å– category
        event_categories = {}
        print("   è·å– event åˆ†ç±»ä¿¡æ¯...")
        for page in range(10):
            try:
                resp = requests.get(f"{API_BASE}/events", params={
                    "limit": 100, "status": "open", "cursor": None
                }, timeout=15)
                if resp.status_code == 200:
                    for e in resp.json().get("events", []):
                        event_categories[e.get("event_ticker", "")] = e.get("category", "Unknown")
                time.sleep(0.2)
            except:
                break
        
        for m in markets:
            ticker = m.get("ticker", "")
            title = m.get("title", "")
            rules = m.get("rules_primary", "")
            event_ticker = m.get("event_ticker", "")
            series_ticker = self.extract_series(ticker, event_ticker)
            category = event_categories.get(event_ticker, m.get("category", "Unknown") or "Unknown")
            volume = m.get("volume_24h", 0) or m.get("volume", 0) or 0
            close_time = m.get("close_time", "")
            
            # æ£€æµ‹ tier
            result = detect_sources(rules, title)
            tier = result.get("research_tier", 9)
            sources = result.get("sources", [])
            
            # æ›´æ–° series ä¿¡æ¯
            s = self.series[series_ticker]
            s["markets"].append({
                "ticker": ticker,
                "title": title[:100],
                "volume": volume,
                "close_time": close_time,
                "tier": tier,
            })
            s["category"] = category
            s["total_volume"] += volume
            
            # ä¿ç•™æœ€å¥½çš„ tier
            if tier < s["tier"]:
                s["tier"] = tier
                s["sources"] = sources
            
            # æ›´æ–°åˆ°æœŸæ—¶é—´èŒƒå›´
            if close_time:
                if not s["earliest_close"] or close_time < s["earliest_close"]:
                    s["earliest_close"] = close_time
                if not s["latest_close"] or close_time > s["latest_close"]:
                    s["latest_close"] = close_time
        
        print(f"   âœ… åˆ†æå®Œæˆï¼Œå…± {len(self.series)} ä¸ª series")
    
    def generate_report(self) -> Dict:
        """ç”ŸæˆæŠ¥å‘Š"""
        now = datetime.now(timezone.utc)
        
        report = {
            "generated_at": now.isoformat(),
            "total_markets": sum(len(s["markets"]) for s in self.series.values()),
            "total_series": len(self.series),
            "by_tier": defaultdict(list),
            "by_category": defaultdict(list),
            "recommended_watchlist": [],
        }
        
        for series_ticker, s in self.series.items():
            tier = s["tier"]
            category = s["category"]
            
            # è®¡ç®—åˆ°æœŸå¤©æ•°
            days_to_earliest = None
            if s["earliest_close"]:
                try:
                    close_time = datetime.fromisoformat(s["earliest_close"].replace("Z", "+00:00"))
                    days_to_earliest = (close_time - now).days
                except:
                    pass
            
            series_info = {
                "series_ticker": series_ticker,
                "category": category,
                "tier": tier,
                "sources": s["sources"],
                "market_count": len(s["markets"]),
                "total_volume": s["total_volume"],
                "days_to_earliest": days_to_earliest,
                "earliest_close": s["earliest_close"],
            }
            
            report["by_tier"][f"tier_{tier}"].append(series_info)
            report["by_category"][category].append(series_info)
            
            # æ¨è watchlist: tier 1-2ï¼Œæœ‰ volume
            if tier <= 2 and s["total_volume"] > 0:
                report["recommended_watchlist"].append(series_info)
        
        # æ’åº
        report["recommended_watchlist"].sort(key=lambda x: (-x["total_volume"]))
        
        return report
    
    def save_census(self, report: Dict):
        """ä¿å­˜æ™®æŸ¥ç»“æœ"""
        DATA_DIR.mkdir(parents=True, exist_ok=True)
        
        # ä¿å­˜å®Œæ•´æŠ¥å‘Š
        with open(CENSUS_FILE, "w") as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        print(f"ğŸ’¾ æ™®æŸ¥ç»“æœå·²ä¿å­˜: {CENSUS_FILE}")
        
        # ä¿å­˜ watchlist
        watchlist = {
            "updated_at": report["generated_at"],
            "series": [s["series_ticker"] for s in report["recommended_watchlist"]],
            "details": report["recommended_watchlist"],
        }
        with open(WATCHLIST_FILE, "w") as f:
            json.dump(watchlist, f, indent=2, ensure_ascii=False)
        print(f"ğŸ’¾ Watchlist å·²ä¿å­˜: {WATCHLIST_FILE}")
    
    def print_summary(self, report: Dict):
        """æ‰“å°æ‘˜è¦"""
        print("\n" + "=" * 60)
        print("ğŸ“Š KALSHI å¸‚åœºæ™®æŸ¥æŠ¥å‘Š")
        print("=" * 60)
        print(f"ç”Ÿæˆæ—¶é—´: {report['generated_at'][:19]}")
        print(f"æ€»å¸‚åœºæ•°: {report['total_markets']}")
        print(f"æ€» Series: {report['total_series']}")
        
        print("\n### æŒ‰ Tier åˆ†å¸ƒ")
        for tier in sorted(report["by_tier"].keys()):
            count = len(report["by_tier"][tier])
            print(f"  {tier}: {count} ä¸ª series")
        
        print("\n### æŒ‰ç±»åˆ«åˆ†å¸ƒ (Top 10)")
        sorted_cats = sorted(report["by_category"].items(), key=lambda x: -len(x[1]))
        for cat, series_list in sorted_cats[:10]:
            print(f"  {cat}: {len(series_list)} ä¸ª series")
        
        print("\n### æ¨è Watchlist (Tier 1-2, æœ‰äº¤æ˜“é‡)")
        watchlist = report["recommended_watchlist"]
        if watchlist:
            print(f"å…± {len(watchlist)} ä¸ª series:\n")
            for s in watchlist[:20]:
                days = s.get("days_to_earliest")
                days_str = f"{days}å¤©" if days else "?"
                print(f"  âœ… {s['series_ticker']:<25} | Tier {s['tier']} | {s['category']:<15} | vol={s['total_volume']:>6} | {days_str}")
                print(f"     Sources: {', '.join(s['sources']) if s['sources'] else '-'}")
        else:
            print("  (æ— )")
        
        print("\n" + "=" * 60)
    
    def fetch_events_by_category(self) -> Dict[str, List[Dict]]:
        """è·å–æ‰€æœ‰ events å¹¶æŒ‰ category åˆ†ç±»"""
        events_by_cat = defaultdict(list)
        cursor = None
        
        print("ğŸ“¡ è·å–æ‰€æœ‰ Events...")
        for page in range(50):
            try:
                params = {"limit": 100, "status": "open"}
                if cursor:
                    params["cursor"] = cursor
                
                resp = requests.get(f"{API_BASE}/events", params=params, timeout=15)
                
                if resp.status_code == 429:
                    time.sleep(5)
                    continue
                
                if resp.status_code != 200:
                    break
                
                data = resp.json()
                batch = data.get("events", [])
                
                for e in batch:
                    cat = e.get("category", "Unknown")
                    events_by_cat[cat].append(e)
                
                cursor = data.get("cursor")
                if not cursor or len(batch) < 100:
                    break
                
                time.sleep(0.2)
                
            except Exception as e:
                print(f"   âŒ Error: {e}")
                break
        
        total = sum(len(v) for v in events_by_cat.values())
        print(f"   âœ… å…± {total} ä¸ª events")
        return dict(events_by_cat)
    
    def fetch_markets_for_events(self, events: List[Dict]) -> List[Dict]:
        """è·å–æŒ‡å®š events çš„æ‰€æœ‰ markets"""
        markets = []
        
        for i, e in enumerate(events):
            try:
                event_ticker = e.get("event_ticker", "")
                if not event_ticker:
                    continue
                
                resp = requests.get(f"{API_BASE}/markets", params={
                    "event_ticker": event_ticker,
                    "status": "open",
                    "limit": 50
                }, timeout=15)
                
                if resp.status_code == 429:
                    time.sleep(5)
                    continue
                
                if resp.status_code == 200:
                    batch = resp.json().get("markets", [])
                    # æ·»åŠ  category ä¿¡æ¯
                    for m in batch:
                        m["_category"] = e.get("category", "Unknown")
                        m["_event_title"] = e.get("title", "")
                        m["_series_ticker"] = e.get("series_ticker", "")
                    markets.extend(batch)
                
                time.sleep(0.15)  # é™æµ
                
                if i % 50 == 0 and i > 0:
                    print(f"   å·²å¤„ç† {i}/{len(events)} ä¸ª events, {len(markets)} ä¸ª markets...")
                
            except Exception as ex:
                pass
        
        return markets
    
    def run(self, summary_only: bool = False):
        """è¿è¡Œå®Œæ•´æ™®æŸ¥"""
        if summary_only and CENSUS_FILE.exists():
            with open(CENSUS_FILE) as f:
                report = json.load(f)
            self.print_summary(report)
            return report
        
        # 1. æ‰«æä¼˜å…ˆ series (ç»æµ/æ”¿æ²»)
        priority_results = self.scan_priority_series()
        
        # 2. ç”ŸæˆæŠ¥å‘Š
        report = self.generate_priority_report(priority_results)
        
        # 3. ä¿å­˜
        self.save_priority_census(report)
        
        # 4. æ‰“å°æ‘˜è¦
        self.print_summary(report)
        
        return report
    
    def generate_priority_report(self, results: Dict[str, Dict]) -> Dict:
        """ä»ä¼˜å…ˆæ‰«æç»“æœç”ŸæˆæŠ¥å‘Š"""
        now = datetime.now(timezone.utc)
        
        report = {
            "generated_at": now.isoformat(),
            "total_series": len(results),
            "total_markets": sum(r["market_count"] for r in results.values()),
            "by_tier": defaultdict(list),
            "by_category": defaultdict(list),
            "recommended_watchlist": [],
            "series": results,
        }
        
        for series, info in results.items():
            tier = info.get("tier", 9)
            
            series_info = {
                "series_ticker": series,
                "tier": tier,
                "sources": info.get("sources", []),
                "research_method": info.get("research_method", ""),
                "market_count": info.get("market_count", 0),
                "total_volume": info.get("total_volume", 0),
                "days_left": info.get("days_left"),
                "earliest_close": info.get("earliest_close"),
                "sample_title": info.get("sample_title", ""),
            }
            
            # åˆ†ç±» (åŸºäº series åç§°æ¨æ–­)
            category = "Unknown"
            if series.startswith("KX"):
                s_lower = series.lower()
                if any(x in s_lower for x in ["gdp", "cpi", "pce", "job", "unemp", "gas"]):
                    category = "Economics"
                elif any(x in s_lower for x in ["fed", "fomc", "rate"]):
                    category = "Fed"
                elif any(x in s_lower for x in ["shutdown", "debt", "dhs", "tariff", "cr", "bill", "eo"]):
                    category = "Government"
                elif any(x in s_lower for x in ["trump", "cabinet", "scotus"]):
                    category = "Politics"
            
            series_info["category"] = category
            
            report["by_tier"][f"tier_{tier}"].append(series_info)
            report["by_category"][category].append(series_info)
            
            # æ¨è: tier 1-2
            if tier <= 2:
                report["recommended_watchlist"].append(series_info)
        
        # æ’åº
        report["recommended_watchlist"].sort(key=lambda x: (x["tier"], -(x.get("total_volume") or 0)))
        
        return report
    
    def save_priority_census(self, report: Dict):
        """ä¿å­˜ä¼˜å…ˆæ‰«æç»“æœ"""
        DATA_DIR.mkdir(parents=True, exist_ok=True)
        
        # ä¿å­˜å®Œæ•´æŠ¥å‘Š
        with open(CENSUS_FILE, "w") as f:
            json.dump(report, f, indent=2, ensure_ascii=False, default=str)
        print(f"ğŸ’¾ æ™®æŸ¥ç»“æœå·²ä¿å­˜: {CENSUS_FILE}")
        
        # ä¿å­˜ watchlist (ä¾› report_v2.py ä½¿ç”¨)
        watchlist = {
            "updated": datetime.now().strftime("%Y-%m-%d %H:%M"),
            "description": "Tier 1-2 å¯ç ”ç©¶å¸‚åœº watchlist (è‡ªåŠ¨ç”Ÿæˆ)",
            "series": [s["series_ticker"] for s in report["recommended_watchlist"]],
            "short_term": [
                s for s in report["recommended_watchlist"] 
                if s.get("days_left") is not None and s["days_left"] <= 90
            ],
            "long_term": [
                s for s in report["recommended_watchlist"]
                if s.get("days_left") is None or s["days_left"] > 90
            ],
        }
        with open(WATCHLIST_FILE, "w") as f:
            json.dump(watchlist, f, indent=2, ensure_ascii=False, default=str)
        print(f"ğŸ’¾ Watchlist å·²ä¿å­˜: {WATCHLIST_FILE}")
        
        # 6. æ‰“å°æ‘˜è¦
        self.print_summary(report)
        
        return report
    
    def analyze_markets_v2(self, markets: List[Dict]):
        """åˆ†æå¸‚åœº V2 - ä½¿ç”¨é¢„ç½®çš„ category ä¿¡æ¯"""
        print("ğŸ” åˆ†æå¸‚åœº...")
        
        for m in markets:
            ticker = m.get("ticker", "")
            title = m.get("title", "")
            rules = m.get("rules_primary", "")
            series_ticker = m.get("_series_ticker") or self.extract_series(ticker, m.get("event_ticker", ""))
            category = m.get("_category", "Unknown")
            volume = m.get("volume_24h", 0) or m.get("volume", 0) or 0
            close_time = m.get("close_time", "")
            
            # æ£€æµ‹ tier
            result = detect_sources(rules, title)
            tier = result.get("research_tier", 9)
            sources = result.get("sources", [])
            
            # æ›´æ–° series ä¿¡æ¯
            s = self.series[series_ticker]
            s["markets"].append({
                "ticker": ticker,
                "title": title[:100],
                "volume": volume,
                "close_time": close_time,
                "tier": tier,
            })
            s["category"] = category
            s["total_volume"] += volume
            
            # ä¿ç•™æœ€å¥½çš„ tier
            if tier < s["tier"]:
                s["tier"] = tier
                s["sources"] = sources
            
            # æ›´æ–°åˆ°æœŸæ—¶é—´èŒƒå›´
            if close_time:
                if not s["earliest_close"] or close_time < s["earliest_close"]:
                    s["earliest_close"] = close_time
                if not s["latest_close"] or close_time > s["latest_close"]:
                    s["latest_close"] = close_time
        
        print(f"   âœ… åˆ†æå®Œæˆï¼Œå…± {len(self.series)} ä¸ª series")


def main():
    parser = argparse.ArgumentParser(description="Kalshi å¸‚åœºæ™®æŸ¥")
    parser.add_argument("--summary", action="store_true", help="åªæ˜¾ç¤ºç°æœ‰æŠ¥å‘Šæ‘˜è¦")
    parser.add_argument("--update", action="store_true", help="æ›´æ–° watchlist")
    
    args = parser.parse_args()
    
    census = MarketCensus()
    census.run(summary_only=args.summary)


if __name__ == "__main__":
    main()
