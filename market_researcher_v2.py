#!/usr/bin/env python3
"""
Market Researcher V2 - åŸºäº Kalshi å®˜æ–¹ç»“ç®—æºçš„äº‹å®æ ¸æŸ¥æ¡†æ¶

æ ¸å¿ƒæ”¹è¿›:
1. ä»å¸‚åœºè§„åˆ™æå–å®˜æ–¹ç»“ç®—æ•°æ®æº
2. LLM åŠ¨æ€è¯†åˆ«éœ€è¦æŸ¥è¯¢çš„é¢å¤–æ•°æ®æº
3. ä¼˜å…ˆä½¿ç”¨å®˜æ–¹æºï¼Œæ¬¡è¦ä½¿ç”¨è¾…åŠ©æº

Author: OpenClaw
Date: 2026-02-20
"""

import os
import sys
import json
import re
from datetime import datetime, timezone
from typing import Optional, Dict, List, Any, Tuple

try:
    import requests
except ImportError:
    requests = None

# å¯¼å…¥ LLM æ•°æ®æºè¯†åˆ«å™¨
try:
    from llm_source_identifier import LLMSourceIdentifier
    HAS_LLM_IDENTIFIER = True
except ImportError:
    HAS_LLM_IDENTIFIER = False


class MarketResearcherV2:
    """
    V2: å®˜æ–¹ç»“ç®—æºä¼˜å…ˆ + LLM åŠ¨æ€æ•°æ®æºè¯†åˆ«
    """
    
    # å·²çŸ¥çš„å®˜æ–¹æ•°æ®æº URL æ˜ å°„
    OFFICIAL_SOURCES = {
        # ç»æµæŒ‡æ ‡
        "bea": "https://www.bea.gov/data/gdp/gross-domestic-product",
        "bls": "https://www.bls.gov/",
        "u-3": "https://www.bls.gov/news.release/empsit.nr0.htm",
        "cpi": "https://www.bls.gov/cpi/",
        "pce": "https://www.bea.gov/data/personal-consumption-expenditures-price-index",
        
        # æ²¹ä»·
        "aaa": "https://gasprices.aaa.com/",
        "eia": "https://www.eia.gov/petroleum/gasdiesel/",
        
        # å¤©æ°”
        "nws": "https://api.weather.gov/",
        "noaa": "https://www.weather.gov/",
        
        # åˆ©ç‡
        "fed": "https://www.federalreserve.gov/monetarypolicy/openmarket.htm",
        "fomc": "https://www.federalreserve.gov/monetarypolicy/fomccalendars.htm",
        "pboc": "http://www.pbc.gov.cn/",
        
        # åŠ å¯†è´§å¸
        "coinmarketcap": "https://coinmarketcap.com/",
        "coingecko": "https://www.coingecko.com/",
        
        # æ–°é—»/æ¼”è®²
        "whitehouse": "https://www.whitehouse.gov/briefing-room/",
        "c-span": "https://www.c-span.org/",
    }
    
    # ç¬¬ä¸‰æ–¹æ•°æ®æº (ç”¨äºäº¤å‰éªŒè¯)
    THIRD_PARTY_SOURCES = {
        "gdp": "https://tradingeconomics.com/united-states/gdp-growth",
        "cpi_te": "https://tradingeconomics.com/united-states/inflation-cpi", 
        "unemployment": "https://tradingeconomics.com/united-states/unemployment-rate",
        "fed_rate": "https://tradingeconomics.com/united-states/interest-rate",
        "gas_te": "https://tradingeconomics.com/commodity/gasoline",
    }
    
    def __init__(self, use_llm=True):
        self.research_log = []
        self.use_llm = use_llm and HAS_LLM_IDENTIFIER
        if self.use_llm:
            self.llm_identifier = LLMSourceIdentifier(provider="gemini")
        else:
            self.llm_identifier = None
        
    def log(self, msg: str):
        ts = datetime.now().strftime("%H:%M:%S")
        self.research_log.append(f"[{ts}] {msg}")
    
    def extract_official_sources(self, market: Dict) -> List[Dict]:
        """
        ä»å¸‚åœºè§„åˆ™ä¸­æå–å®˜æ–¹ç»“ç®—æ•°æ®æº
        
        Returns:
            [{"source": "BLS", "url": "...", "data_type": "unemployment"}, ...]
        """
        rules = market.get('rules_primary', '') + ' ' + market.get('rules_secondary', '')
        rules_lower = rules.lower()
        
        sources = []
        
        # æ¨¡å¼åŒ¹é…å®˜æ–¹æ•°æ®æº
        patterns = [
            (r'u-3\s*unemployment', 'BLS', 'u-3', 'unemployment'),
            (r'bls|bureau of labor', 'BLS', 'bls', 'labor'),
            (r'bea|bureau of economic', 'BEA', 'bea', 'gdp'),
            (r'gdp|gross domestic', 'BEA', 'bea', 'gdp'),
            (r'cpi|consumer price', 'BLS', 'cpi', 'inflation'),
            (r'pce|personal consumption', 'BEA', 'pce', 'inflation'),
            (r'aaa.*gas|gas.*aaa', 'AAA', 'aaa', 'gas_price'),
            (r'eia.*gas|gas.*eia', 'EIA', 'eia', 'gas_price'),
            (r'nws|national weather|weather\.gov', 'NWS', 'nws', 'weather'),
            (r'federal reserve|fomc|fed fund', 'Fed', 'fed', 'interest_rate'),
            (r'pboc|people.s bank', 'PBOC', 'pboc', 'interest_rate'),
        ]
        
        for pattern, name, key, data_type in patterns:
            if re.search(pattern, rules_lower):
                url = self.OFFICIAL_SOURCES.get(key, '')
                sources.append({
                    "source": name,
                    "url": url,
                    "data_type": data_type,
                    "is_official": True,
                })
        
        self.log(f"ä»è§„åˆ™æå–åˆ° {len(sources)} ä¸ªå®˜æ–¹æ•°æ®æº: {[s['source'] for s in sources]}")
        return sources
    
    def identify_additional_sources(self, market: Dict, official_sources: List[Dict]) -> List[Dict]:
        """
        LLM åŠ¨æ€è¯†åˆ«éœ€è¦æŸ¥è¯¢çš„é¢å¤–æ•°æ®æº
        
        ä¼˜å…ˆä½¿ç”¨ LLMï¼Œå›é€€åˆ°è§„åˆ™
        """
        # å°è¯•ä½¿ç”¨ LLM
        if self.use_llm and self.llm_identifier:
            try:
                llm_result = self.llm_identifier.identify_sources(market)
                additional = []
                
                # è½¬æ¢ LLM è¾“å‡ºæ ¼å¼
                for s in llm_result.get('sources', []):
                    # è·³è¿‡å·²ç»åœ¨ official_sources ä¸­çš„
                    if any(s['name'].lower() in os.get('source', '').lower() for os in official_sources):
                        continue
                    
                    source = {
                        "source": s['name'],
                        "url": s.get('url'),
                        "data_type": s.get('data_to_fetch', ''),
                        "is_official": s.get('type') == 'official',
                        "purpose": s.get('data_to_fetch', ''),
                    }
                    
                    if not s.get('verifiable_before_settlement', True):
                        source["warning"] = True
                    
                    additional.append(source)
                
                # å¦‚æœ LLM è¯´ä¸å¯éªŒè¯ï¼Œæ·»åŠ è­¦å‘Š
                if not llm_result.get('verifiable', True):
                    additional.append({
                        "source": "âš ï¸ LLMåˆ¤æ–­ä¸å¯æ ¸æŸ¥",
                        "url": None,
                        "data_type": "unverifiable",
                        "is_official": False,
                        "purpose": llm_result.get('reason', 'æ— æ³•æå‰éªŒè¯'),
                        "warning": True,
                    })
                
                self.log(f"LLMè¯†åˆ«åˆ° {len(additional)} ä¸ªé¢å¤–æ•°æ®æº")
                return additional
                
            except Exception as e:
                self.log(f"LLMè¯†åˆ«å¤±è´¥: {e}ï¼Œä½¿ç”¨è§„åˆ™å›é€€")
        
        # è§„åˆ™å›é€€
        title = market.get('title', '').lower()
        additional = []
        
        # åŸºäºé—®é¢˜ç±»å‹è¯†åˆ«é¢å¤–æ•°æ®æº
        if any(k in title for k in ['gdp', 'economic growth']):
            # GDP éœ€è¦ GDPNow é¢„æµ‹ + å†å²æ•°æ®
            additional.append({
                "source": "Atlanta Fed GDPNow",
                "url": "https://www.atlantafed.org/cqer/research/gdpnow",
                "data_type": "gdp_forecast",
                "is_official": False,
                "purpose": "å®æ—¶é¢„æµ‹å‚è€ƒ (æ³¨æ„è¯¯å·®é£é™©)",
            })
            additional.append({
                "source": "Trading Economics",
                "url": self.THIRD_PARTY_SOURCES.get('gdp'),
                "data_type": "gdp_history",
                "is_official": False,
                "purpose": "å†å²æ•°æ® + é¢„æµ‹",
            })
        
        elif any(k in title for k in ['unemployment', 'jobless']):
            additional.append({
                "source": "Trading Economics",
                "url": self.THIRD_PARTY_SOURCES.get('unemployment'),
                "data_type": "unemployment",
                "is_official": False,
                "purpose": "å†å²è¶‹åŠ¿ + é¢„æµ‹",
            })
        
        elif any(k in title for k in ['gas price', 'gasoline']):
            additional.append({
                "source": "Trading Economics",
                "url": self.THIRD_PARTY_SOURCES.get('gas_te'),
                "data_type": "gas_commodity",
                "is_official": False,
                "purpose": "æœŸè´§ä»·æ ¼è¶‹åŠ¿",
            })
        
        elif any(k in title for k in ['trump', 'biden', 'president']) and any(k in title for k in ['say', 'mention', 'tweet']):
            additional.append({
                "source": "White House",
                "url": self.OFFICIAL_SOURCES.get('whitehouse'),
                "data_type": "speeches",
                "is_official": True,
                "purpose": "å®˜æ–¹è®²è¯è®°å½•",
            })
            additional.append({
                "source": "âš ï¸ æ— æ³•æå‰æ ¸æŸ¥",
                "url": None,
                "data_type": "future_speech",
                "is_official": False,
                "purpose": "æœªæ¥å‘è¨€æ— æ³•é¢„æµ‹",
                "warning": True,
            })
        
        self.log(f"è¯†åˆ«åˆ° {len(additional)} ä¸ªé¢å¤–æ•°æ®æº")
        return additional
    
    def fetch_source(self, source: Dict) -> Optional[Dict]:
        """
        è·å–å•ä¸ªæ•°æ®æºçš„æ•°æ®
        """
        url = source.get('url')
        if not url or not requests:
            return None
        
        try:
            headers = {"User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7)"}
            resp = requests.get(url, headers=headers, timeout=15)
            if resp.status_code != 200:
                self.log(f"è·å–å¤±è´¥ {source['source']}: HTTP {resp.status_code}")
                return None
            
            content = resp.text
            result = {
                "source": source['source'],
                "url": url,
                "data_type": source.get('data_type'),
                "is_official": source.get('is_official', False),
                "raw_length": len(content),
                "content": content[:3000],
            }
            
            # å°è¯•æå–æ•°å€¼
            result["extracted"] = self._extract_values(content, source.get('data_type'))
            
            self.log(f"è·å–æˆåŠŸ {source['source']}: {len(content)} chars, extracted={result['extracted']}")
            return result
            
        except Exception as e:
            self.log(f"è·å–é”™è¯¯ {source['source']}: {e}")
            return None
    
    def _extract_values(self, content: str, data_type: str) -> Dict:
        """
        ä»å†…å®¹ä¸­æå–æ•°å€¼
        """
        result = {}
        
        if data_type == "gas_price":
            # AAA æ ¼å¼
            prices = re.findall(r'\$(\d+\.\d{3})', content)
            if prices:
                result["current"] = float(prices[0])
                result["values"] = [float(p) for p in prices[:5]]
        
        elif data_type in ["gdp", "gdp_history"]:
            # Trading Economics æ ¼å¼
            match = re.search(r'expanded?\s+(\d+\.?\d*)\s*percent', content.lower())
            if match:
                result["current"] = float(match.group(1))
        
        elif data_type == "unemployment":
            # BLS æ ¼å¼
            match = re.search(r'unemployment rate.*?(\d+\.?\d*)\s*percent', content.lower())
            if match:
                result["current"] = float(match.group(1))
        
        elif data_type == "inflation":
            match = re.search(r'inflation.*?(\d+\.?\d*)\s*percent', content.lower())
            if match:
                result["current"] = float(match.group(1))
        
        return result
    
    def research(self, market: Dict) -> Dict:
        """
        å¯¹å¸‚åœºè¿›è¡Œå®Œæ•´ç ”ç©¶
        
        Returns:
            {
                "market": {...},
                "official_sources": [...],
                "additional_sources": [...],
                "data": [...],
                "judgment": {...},
                "research_log": [...]
            }
        """
        self.research_log = []
        self.log(f"=== å¼€å§‹ç ”ç©¶: {market.get('ticker', '?')} ===")
        self.log(f"é—®é¢˜: {market.get('title', '')[:60]}...")
        
        # Step 1: æå–å®˜æ–¹æ•°æ®æº
        official = self.extract_official_sources(market)
        
        # Step 2: è¯†åˆ«é¢å¤–æ•°æ®æº
        additional = self.identify_additional_sources(market, official)
        
        # Step 3: æ£€æŸ¥æ˜¯å¦å¯æ ¸æŸ¥
        all_sources = official + additional
        warnings = [s for s in all_sources if s.get('warning')]
        
        if warnings:
            self.log(f"âš ï¸ å‘ç°ä¸å¯æ ¸æŸ¥é¡¹: {[w['source'] for w in warnings]}")
        
        # Step 4: è·å–æ•°æ®
        data = []
        for source in all_sources:
            if source.get('warning'):
                continue
            fetched = self.fetch_source(source)
            if fetched:
                data.append(fetched)
        
        # Step 5: åšå‡ºåˆ¤æ–­
        judgment = self._make_judgment(market, data, warnings)
        
        self.log(f"=== ç ”ç©¶å®Œæˆ ===")
        
        return {
            "market": market,
            "official_sources": official,
            "additional_sources": additional,
            "data": data,
            "judgment": judgment,
            "research_log": self.research_log.copy(),
        }
    
    def _make_judgment(self, market: Dict, data: List[Dict], warnings: List[Dict]) -> Dict:
        """
        åŸºäºæ”¶é›†çš„æ•°æ®åšå‡ºåˆ¤æ–­
        """
        judgment = {
            "direction": "UNCERTAIN",
            "confidence": 0,
            "reasoning": "",
            "key_facts": [],
            "risks": [],
            "recommendation": "SKIP",
            "position_size": "none",
            "data_sources_used": len(data),
            "has_official_data": any(d.get('is_official') for d in data),
        }
        
        # å¦‚æœæœ‰ä¸å¯æ ¸æŸ¥è­¦å‘Šï¼Œç›´æ¥è·³è¿‡
        if warnings:
            judgment["reasoning"] = f"å­˜åœ¨ä¸å¯æ ¸æŸ¥é¡¹: {[w['source'] for w in warnings]}"
            judgment["risks"].append("æ— æ³•æå‰éªŒè¯")
            self.log("åˆ¤æ–­: SKIP (ä¸å¯æ ¸æŸ¥)")
            return judgment
        
        # å¦‚æœæ²¡æœ‰æ•°æ®ï¼Œè·³è¿‡
        if not data:
            judgment["reasoning"] = "æ— æ³•è·å–æ•°æ®"
            judgment["risks"].append("æ•°æ®æºä¸å¯ç”¨")
            self.log("åˆ¤æ–­: SKIP (æ— æ•°æ®)")
            return judgment
        
        # æå–é˜ˆå€¼
        title = market.get('title', '')
        threshold = None
        
        # å°è¯•æå–æ•°å€¼é˜ˆå€¼
        thresh_match = re.search(r'(?:above|below|more than|less than|over|under)[^\d]*(\d+\.?\d*)', title.lower())
        if thresh_match:
            threshold = float(thresh_match.group(1))
            judgment["key_facts"].append(f"é˜ˆå€¼: {threshold}")
        
        # è·å–å½“å‰å€¼
        current_value = None
        for d in data:
            if d.get('extracted', {}).get('current'):
                current_value = d['extracted']['current']
                judgment["key_facts"].append(f"å½“å‰å€¼: {current_value} (æ¥æº: {d['source']})")
                break
        
        # å¦‚æœæœ‰é˜ˆå€¼å’Œå½“å‰å€¼ï¼Œè¿›è¡Œæ¯”è¾ƒ
        if threshold is not None and current_value is not None:
            gap = current_value - threshold
            gap_pct = (gap / threshold) * 100 if threshold != 0 else 0
            
            # åˆ¤æ–­é€»è¾‘
            if 'above' in title.lower() or 'more than' in title.lower() or 'over' in title.lower():
                # é—®çš„æ˜¯æ˜¯å¦è¶…è¿‡é˜ˆå€¼
                if gap > 0:
                    judgment["direction"] = "YES"
                    judgment["confidence"] = min(90, 50 + abs(gap_pct) * 2)
                    judgment["reasoning"] = f"å½“å‰ {current_value} > é˜ˆå€¼ {threshold}"
                elif gap > -abs(threshold * 0.05):  # 5%ä»¥å†…
                    judgment["direction"] = "UNCERTAIN"
                    judgment["confidence"] = 30
                    judgment["reasoning"] = f"å½“å‰ {current_value} æ¥è¿‘é˜ˆå€¼ {threshold}"
                    judgment["risks"].append("è¾¹ç•Œé£é™©")
                else:
                    judgment["direction"] = "NO"
                    judgment["confidence"] = min(90, 50 + abs(gap_pct) * 2)
                    judgment["reasoning"] = f"å½“å‰ {current_value} < é˜ˆå€¼ {threshold}"
            else:
                # é—®çš„æ˜¯æ˜¯å¦ä½äºé˜ˆå€¼ (below/less than/under)
                if gap < 0:
                    judgment["direction"] = "YES"
                    judgment["confidence"] = min(90, 50 + abs(gap_pct) * 2)
                    judgment["reasoning"] = f"å½“å‰ {current_value} < é˜ˆå€¼ {threshold}"
                else:
                    judgment["direction"] = "NO"
                    judgment["confidence"] = min(90, 50 + abs(gap_pct) * 2)
                    judgment["reasoning"] = f"å½“å‰ {current_value} > é˜ˆå€¼ {threshold}"
        else:
            judgment["reasoning"] = "æ— æ³•æå–é˜ˆå€¼æˆ–å½“å‰å€¼è¿›è¡Œæ¯”è¾ƒ"
            judgment["risks"].append("éœ€è¦äººå·¥åˆ†æ")
        
        # è®¾ç½®æ¨è
        if judgment["confidence"] >= 70 and judgment["has_official_data"]:
            judgment["recommendation"] = "BUY"
            judgment["position_size"] = "half" if judgment["confidence"] < 80 else "full"
        elif judgment["confidence"] >= 50:
            judgment["recommendation"] = "WAIT"
            judgment["position_size"] = "quarter"
        else:
            judgment["recommendation"] = "SKIP"
            judgment["position_size"] = "none"
        
        self.log(f"åˆ¤æ–­: {judgment['direction']} ({judgment['confidence']}%) â†’ {judgment['recommendation']}")
        return judgment
    
    def format_report(self, report: Dict) -> str:
        """æ ¼å¼åŒ–ç ”ç©¶æŠ¥å‘Š"""
        m = report['market']
        j = report['judgment']
        
        lines = [
            f"ğŸ“Š ç ”ç©¶æŠ¥å‘Š: {m.get('ticker', '?')}",
            f"é—®é¢˜: {m.get('title', '')[:60]}...",
            f"å½“å‰ä»·æ ¼: {m.get('last_price', '?')}Â¢",
            "",
            "ğŸ” æ•°æ®æº:",
        ]
        
        # å®˜æ–¹æ•°æ®æº
        for s in report['official_sources']:
            lines.append(f"  âœ… {s['source']} (å®˜æ–¹) - {s['data_type']}")
        
        # é¢å¤–æ•°æ®æº
        for s in report['additional_sources']:
            if s.get('warning'):
                lines.append(f"  âš ï¸ {s['source']} - {s.get('purpose', '')}")
            else:
                lines.append(f"  ğŸ“ {s['source']} - {s.get('purpose', '')}")
        
        lines.extend([
            "",
            f"ğŸ“ˆ åˆ¤æ–­: {j['direction']}",
            f"ğŸ¯ ç½®ä¿¡åº¦: {j['confidence']}%",
            f"ğŸ’¡ ç†ç”±: {j['reasoning']}",
        ])
        
        if j['key_facts']:
            lines.append(f"ğŸ“‹ å…³é”®äº‹å®: {', '.join(j['key_facts'])}")
        
        if j['risks']:
            lines.append(f"âš ï¸ é£é™©: {', '.join(j['risks'])}")
        
        lines.extend([
            "",
            f"âœ… æ¨è: {j['recommendation']}",
            f"ğŸ“¦ ä»“ä½: {j['position_size']}",
        ])
        
        return "\n".join(lines)


def test():
    """æµ‹è¯•å‡½æ•°"""
    researcher = MarketResearcherV2()
    
    # æµ‹è¯•å¤±ä¸šç‡å¸‚åœº
    unemployment_market = {
        'ticker': 'KXU3MAX-30-10',
        'title': 'Will unemployment go above 10% before 2030?',
        'last_price': 37,
        'rules_primary': 'If the U-3 unemployment rate is above 10%, the market resolves to Yes.',
    }
    
    print("=== æµ‹è¯•å¤±ä¸šç‡å¸‚åœº ===")
    report = researcher.research(unemployment_market)
    print(researcher.format_report(report))
    print()
    
    # æµ‹è¯• Trump è¯´è¯å¸‚åœº (ä¸å¯æ ¸æŸ¥)
    trump_market = {
        'ticker': 'KXTRUMPSAY-CRYPTO',
        'title': 'Will Trump say "crypto" in his next speech?',
        'last_price': 65,
        'rules_primary': 'Resolves Yes if Trump says the word crypto in a speech.',
    }
    
    print("=== æµ‹è¯• Trump è¯´è¯å¸‚åœº ===")
    report2 = researcher.research(trump_market)
    print(researcher.format_report(report2))


if __name__ == "__main__":
    test()
